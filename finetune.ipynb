{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87d148c-293b-4d36-9e9a-43d86bcc49e9",
   "metadata": {},
   "source": [
    "### This notebooks is based on the github repo: https://github.com/tloen/alpaca-lora. Credit to  Avatar Eric J. Wang "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd7093b7-15c0-49e3-b950-18efc5cdf01b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /home/ec2-user/anaconda3/envs/pytorch_p39/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "import utils\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4ea4f3-cf4f-491a-9d14-d5eecfbf0ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer,GenerationConfig\n",
    "from peft import (\n",
    "    PeftModel,\n",
    "    prepare_model_for_int8_training,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ddeb5-622b-4c04-bc31-9e49281a1aa5",
   "metadata": {},
   "source": [
    "### (1) Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f213f28e-b3d3-4d9e-9406-dfac7b7f7f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MICRO_BATCH_SIZE = 4\n",
    "BATCH_SIZE = 64 #128\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 3e-4\n",
    "CUTOFF_LEN = 256\n",
    "LORA_R = 8\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT = 0.05\n",
    "VAL_SET_RATIO = 0.2\n",
    "TARGET_MODULES = [\n",
    "    \"q_proj\",\n",
    "    \"v_proj\",\n",
    "]\n",
    "\n",
    "DATA_PATH = \"./hong_kong_consumption_voucher_scheme_datasets_for_tunning.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356bfb33-190d-4f84-9fbf-e0b6d142d53c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n",
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006867408752441406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c367f85be142268ae828466324f7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device_map = \"auto\"\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\")\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"decapoda-research/llama-7b-hf\",\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "### load model after fine tuned on alpaca datasets\n",
    "model = PeftModel.from_pretrained(model, \"tloen/alpaca-lora-7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e81522-8784-4df4-9bdd-f5e3dfb84214",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (2) Load Fine Tunning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a878153b-b8c2-4644-8b25-d8f5f55bdec0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/ec2-user/.cache/huggingface/datasets/json/default-4bfdefce5232ac63/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005761146545410156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05af4d63c064fafbe841e4ad6aa4d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f48a24-b871-493e-a9df-3648303841de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VAL_SET_SIZE = int(VAL_SET_RATIO*len(data['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb8d870-528d-4021-bda4-3ac8f36857cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/ec2-user/.cache/huggingface/datasets/json/default-4bfdefce5232ac63/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-6cd8d1baf605df32.arrow and /home/ec2-user/.cache/huggingface/datasets/json/default-4bfdefce5232ac63/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-227264b836a6cd59.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val = data[\"train\"].train_test_split(\n",
    "    test_size=VAL_SET_SIZE, shuffle=True, seed=42\n",
    ")\n",
    "train_data = train_val[\"train\"]\n",
    "val_data = train_val[\"test\"]\n",
    "\n",
    "round(len(train_data)/(len(train_data)+len(val_data)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "396d185f-88b9-4dbc-91c4-fd1ced77d9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt_eval(instruction):\n",
    "    template =  f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{instruction}\n",
    "### Response:\"\"\"\n",
    "    return template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42a1e91b-4463-43fd-90bd-40a1409e2ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt_train(inputs):\n",
    "    instruction = inputs['instruction']\n",
    "    output = inputs['output']\n",
    "    template =  f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{instruction}\n",
    "### Response:\n",
    "{output}\"\"\"\n",
    "    return template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4478c141-9b17-4b76-a6ef-604959ad95b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_generation_config = GenerationConfig(\n",
    "    temperature=0.1,\n",
    "    top_p=0.75,\n",
    "    num_beams=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f0d6074-3d67-429d-aed8-4d5d9c32faa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id = 0\n",
    "def tokenize(prompt):\n",
    "    # there's probably a way to do this with the tokenizer settings\n",
    "    # but again, gotta move fast\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=CUTOFF_LEN + 1,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": result[\"input_ids\"][:-1],\n",
    "        \"attention_mask\": result[\"attention_mask\"][:-1],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "115be742-4d36-4ab8-9cd6-ffb7ebbcf62c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_answer(data_item):\n",
    "    prompt = generate_prompt_eval(data_item)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].cuda()\n",
    "    generation_output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        generation_config=eval_generation_config,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=256\n",
    "    )\n",
    "    for s in generation_output.sequences:\n",
    "        output = tokenizer.decode(s)\n",
    "        answer = output.split(\"### Response:\")[1].strip()\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0df0cc46-6785-4712-9f73-13f02fde7760",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0050542354583740234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 18,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004921674728393555,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 4,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_data.shuffle().map(lambda x: tokenize(generate_prompt_train(x)))\n",
    "val_dataset = val_data.shuffle().map(lambda x: tokenize(generate_prompt_train(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c2dd0-f6eb-4217-a0a5-1969a61c5095",
   "metadata": {},
   "source": [
    "### (3) Evaluate before further fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8de20f04-61f4-4c8c-ab66-ef893bbd13d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset  = utils.open_json(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f771d966-6553-431b-9370-4e35f17aeb0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = random.choice(dataset)\n",
    "\n",
    "instruction = sample['instruction']\n",
    "output = sample['output']\n",
    "print(\"instruction:\",instruction)\n",
    "print(\"ground truth:\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c150dc36-6a55-4a5b-9e1a-0a1abf343eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, eligible people who have passed away will not be able to receive the first- instalment voucher on 16 April.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d11ed2e-bda4-480e-926e-b242411d522e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "url = 'https://www.google.com/search?q=python'\n",
      "\n",
      "r = requests.get(url)\n",
      "soup = BeautifulSoup(r.text, 'html.parser')\n",
      "\n",
      "for link in soup.find_all('a'):\n",
      "    print(link.get('href'))\n"
     ]
    }
   ],
   "source": [
    "question = \"Write a python script to get the google search result using beautifulsoup\"\n",
    "answer = generate_answer(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8c5e67-687d-425d-b6c0-7e3f510718e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  (4) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec9d1c15-94ae-48f0-8a5d-783493091297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_step_per_epoch = len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1d1283b-bd14-4566-b751-d4bcd80bc99e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(num_step_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17ba7d80-aea7-4c3d-9195-153eb610d4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67541ca4-84f1-4d8f-b985-e105efbcdbab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
    "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "        warmup_steps=num_step_per_epoch,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        fp16=True,\n",
    "        logging_steps=20,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=num_step_per_epoch*10,\n",
    "        save_steps=num_step_per_epoch*10,\n",
    "        output_dir=\"lora-alpaca\",\n",
    "        save_total_limit=3,\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31c5cfa0-306a-44d0-b63c-5e1008351187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6da9ab8b-0ab3-4b97-b1c6-46662b820ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "old_state_dict = model.state_dict\n",
    "\n",
    "model.state_dict = (\n",
    "    lambda self, *_, **__: get_peft_model_state_dict(self, old_state_dict())\n",
    ").__get__(model, type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "364b2a60-1600-43a7-a58c-364f8c2ae382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 02:59, Epoch 40/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=0.28849071502685547, metrics={'train_runtime': 183.8235, 'train_samples_per_second': 4.896, 'train_steps_per_second': 0.272, 'total_flos': 7311832016486400.0, 'train_loss': 0.28849071502685547, 'epoch': 40.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812196f1-6874-46dc-82bc-71128dfb4a59",
   "metadata": {},
   "source": [
    "### (4) Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "888ced03-df17-4dc0-a8c9-b9029b05b9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instruction: Can eligible people who have passed away receive the first- instalment voucher on 16 April?\n",
      "ground truth: Consumption voucher will not be disbursed on 16 April to eligible people who have passed away after successfully registered under 2022 CVS.\n"
     ]
    }
   ],
   "source": [
    "instruction = sample['instruction']\n",
    "output = sample['output']\n",
    "print(\"instruction:\",instruction)\n",
    "print(\"ground truth:\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16b5bce0-5716-4511-9297-997b3ce9fe5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are sorry to inform people who have passed away that they will not receive the first-instalment voucher on 16 April.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa7627b2-0075-4193-9242-c8031fa3456a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "url = 'https://www.google.com/search?q={search_term}'.format(search_term=search_term)\n",
      "r = requests.get(url)\n",
      "soup = BeautifulSoup(r.text, 'lxml')\n",
      "\n",
      "for link in soup.select('a[href]'):\n",
      "    print(link['href'])\n"
     ]
    }
   ],
   "source": [
    "question_4 = \"Write a python script to get the google search result using beautifulsoup\"\n",
    "answer = generate_answer(question_4)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd3bef-eb7a-4fbc-a7f3-05c3368deec0",
   "metadata": {},
   "source": [
    "### (5) Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "669d6d84-99f2-4916-a2f5-70a77391186d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving model\n",
    "model_name_or_path = \"alpaca-lora-7b-tuned-on-hk-cvs-fqa\"\n",
    "# peft_type = \"PROMPT_TUNING\"\n",
    "# task_type = \"CAUSAL_LM\"\n",
    "\n",
    "peft_model_id = model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e50fe859-5ea2-44ba-a52a-30a7a4ae5c96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpaca-lora-7b-tuned-on-hk-cvs-fqa\n"
     ]
    }
   ],
   "source": [
    "print(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b715e22-b1a2-49c7-9d21-3958a095710a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c0743-e127-45ff-898d-7c3070e0a5f6",
   "metadata": {},
   "source": [
    "### (5) Upload to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d4e9f02-2cdc-47d5-bfee-969db486e6b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: huggingface_hub in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface_hub) (4.63.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface_hub) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface_hub) (4.4.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface_hub) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface_hub) (5.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface_hub) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface_hub) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "631be789-7230-4541-8ab1-1274392a1e62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d391ff62-0031-4d00-b089-edad15d0cfc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b7bf52671144719ca40ae7fb73d84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a20c4385-3394-4ef9-9086-fb49b9baafc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007355213165283203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "adapter_model.bin",
       "rate": null,
       "total": 16822989,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362fd50a97884527be4647d08e268493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.bin:   0%|          | 0.00/16.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0063686370849609375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload 1 LFS files",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81816b097bb749f6adcfd7df83dda0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Nelsonlin0321/alpaca-lora-7b-tuned-on-hk-cvs-fqa/commit/3be83b36444580e12231f01f648d96429a9b70a9', commit_message='Upload model', commit_description='', oid='3be83b36444580e12231f01f648d96429a9b70a9', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(f\"Nelsonlin0321/{peft_model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d9d64b-a2ce-4ffa-ae4c-4f74a626e7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
